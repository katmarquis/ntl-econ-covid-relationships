# -*- coding: utf-8 -*-
"""Final Preprocessing and Feature Engineering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cGSVnN-MqZneKNQGzM5ezt8KnOqLTeow
"""

import pandas as pd
import numpy as np
from scipy import stats

from google.colab import drive
from google.colab import files
drive.mount('/content/drive')

path = "/content/drive/MyDrive/Undergrad/Junior Summer/SURF/data/"

"""## Conversion of Units for Land Area"""

data = pd.read_csv(path + "county_area.csv",index_col=0)
data = data.rename(columns={"Land_Area": "Land_Area_m2"})

mi2 = []

for row in data.itertuples():
  meters = row.Land_Area_m2
  miles = meters * 3.8610192 * 10**(-7)
  mi2.append(miles)

data["Land_Area_mi2"] = mi2
data.to_csv(path + "county_area.csv")
data.head()

"""## Combine Dataframes"""

ntl_data = pd.read_csv(path + "ntl_data.csv", index_col=0)
covid_and_ec_data = pd.read_csv(path + "county_cases_deaths_vax_policy_ec.csv",index_col=0)

covid_and_ec_data.head()

def from_date(date_string):
  date_lst = date_string.split("-")
  year = date_lst[0]
  year = float(year)
  month = date_lst[1]
  month = float(month)
  return (month, year)

months = []
years = []

for row in ntl_data.itertuples():
  date_str = row.Date
  month, year = from_date(date_str)
  months.append(month)
  years.append(year)

ntl_data["Date_Month"] = months
ntl_data["Date_Year"] = years

ntl_data.head()

means = []
devs = []
sols = []
stands = []
dates = []

for row in covid_and_ec_data.itertuples():
  m = row.Month
  y = row.Year
  fips = row.FIPS
  ntl_row = ntl_data[(ntl_data["FIPS"] == fips) & (ntl_data["Date_Month"] == m) & (ntl_data["Date_Year"] == y)]
  ntl_row.reset_index(drop=True)
  mean = ntl_row.iloc[0]["Mean"]
  dev = ntl_row.iloc[0]["Std_Dev"]
  sol = ntl_row.iloc[0]["Sum_of_Lights"]
  stand = ntl_row.iloc[0]["Standard_SoL"]
  date = ntl_row.iloc[0]["Date"]
  means.append(mean)
  devs.append(dev)
  sols.append(sol)
  stands.append(stand)
  dates.append(date)

covid_and_ec_data["Date"] = dates
covid_and_ec_data["NTL_Mean"] = means
covid_and_ec_data["NTL_Std_Dev"] = devs
covid_and_ec_data["NTL_SOL"] = sols
covid_and_ec_data["NTL_SOL_Standardized"] = stands

covid_and_ec_data.to_csv(path + "combined_data.csv")
covid_and_ec_data.head()

covid_and_ec_data = pd.read_csv(path + "combined_data.csv",index_col=0)
land_area_df = pd.read_csv(path + "county_area.csv",index_col=0)

land_area_dict = {}
for row in land_area_df.itertuples():
  fips = row.County
  area = row.Land_Area_mi2
  land_area_dict[fips] = area

areas = []
for row in covid_and_ec_data.itertuples():
  fips = row.FIPS
  area = land_area_dict[fips]
  areas.append(area)

covid_and_ec_data["County_Land_Area_mi2"] = areas
covid_and_ec_data.to_csv(path + "combined_data.csv")

"""## Calculate Incidence Rate, Mortality Rate, and Fatality Ratio"""

data = pd.read_csv(path + "combined_data.csv",index_col=0)
data.head()

inc_rate = []
d_rate = []
fatality_rat = []
inc_rate_tot = []
d_rate_tot = []
fatality_rat_tot = []

for row in data.itertuples():
  pop = row.Population
  cases_new = row.New_Cases
  cases_tot = row.Total_Cases
  deaths_new = row.New_Deaths
  deaths_tot = row.Total_Deaths
  inc_rate.append(100000 * cases_new/pop)
  d_rate.append(100000 * deaths_new/pop)
  if cases_new != 0:
    fatality_rat.append(deaths_new/cases_new)
  elif cases_new == 0:
    fatality_rat.append(0)
  inc_rate_tot.append(100000 * cases_tot/pop)
  d_rate_tot.append(100000 * deaths_tot/pop)
  if cases_tot != 0:
    fatality_rat_tot.append(deaths_tot/cases_tot)
  elif cases_tot == 0:
    recent = fatality_rat_tot[-1]
    fatality_rat_tot.append(recent)

data["Incidence_Rate"] = inc_rate
data["Death_Rate"] = d_rate
data["Fatality_Ratio"] = fatality_rat
data["Cumulative_Incidence_Rate"] = inc_rate_tot
data["Cumulative_Death_Rate"] = d_rate_tot
data["Cumulative_Fatality_Ratio"] = fatality_rat_tot

data.to_csv(path + "combined_data_and_covid_calcs.csv")
data.head()

"""## Calculate Population Density"""

data = pd.read_csv(path + "combined_data_and_covid_calcs.csv",index_col=0)
pop_dens = []
for row in data.itertuples():
  p = row.Population
  a = row.County_Land_Area_mi2
  pop_dens.append(p/a)
data["Population_Density"] = pop_dens
data.sample(n=5)

data.to_csv(path + "combined_data_and_ppl_calcs.csv")

"""## Calculate Normality Divergence"""

past_data = pd.read_csv(path + "past_ntl_data.csv", index_col=0)
curr_data = pd.read_csv(path + "combined_data_and_ppl_calcs.csv", index_col=0)

def get_month_and_year(date_str):
  date_lst = date_str.split("-")
  y = date_lst[0]
  m = date_lst[1]
  y = float(y)
  m = float(m)
  return [m,y]

months = []
years = []

for row in past_data.itertuples():
  date = row.Date
  date_lst = get_month_and_year(date)
  months.append(date_lst[0])
  years.append(date_lst[1])

past_data["Month"] = months
past_data["Year"] = years

past_data.head()

divergence = []

for row in curr_data.itertuples():
  m = row.Month
  fips = row.FIPS
  past_rows = past_data[(past_data["FIPS"] == fips) & (past_data["Month"] == m) & (past_data["Year"] < 2020)]
  sols = past_rows["Sum_of_Lights"].tolist()
  if sols == [0,0]:
    divergence.append(0)
  elif sols != [0,0]:
    past_avg = sum(sols)/len(sols)
    if row.NTL_SOL == 0:
      divergence.append(0)
    elif row.NTL_SOL != 0:
      div = (row.NTL_SOL - past_avg)/(past_avg)
      divergence.append(div)

curr_data["NTL_Normality_Divergence"] = divergence
curr_data.to_csv(path + "data_final_unscaled.csv")
curr_data.head()

"""## Scale NTL by Population and Population Density

### Current Data
"""

data = pd.read_csv(path + "data_final_unscaled.csv", index_col=0)

mean1 = []
std_dev1 = []
sol1 = []
stand_sol1 = []
norm1 = []
mean2 = []
std_dev2 = []
sol2 = []
stand_sol2 = []
norm2 = []

for row in data.itertuples():
  p = row.Population
  dens = row.Population_Density
  m = row.NTL_Mean
  d = row.NTL_Std_Dev
  s = row.NTL_SOL
  ss = row.NTL_SOL_Standardized
  n = row.NTL_Normality_Divergence
  mean1.append(100000 * m/p)
  std_dev1.append(100000 * d/p)
  sol1.append(100000 * s/p)
  stand_sol1.append(100000 * ss/p)
  norm1.append(100000 * n/dens)
  mean2.append(100000 * m/dens)
  std_dev2.append(100000 * d/dens)
  sol2.append(100000 * s/dens)
  stand_sol2.append(100000 * ss/dens)
  norm2.append(100000 * n/dens)

data["NTL_Mean_wrt_Population"] = mean1
data["NTL_Std_Dev_wrt_Population"] = std_dev1
data["NTL_SOL_wrt_Population"] = sol1
data["NTL_SOL_Standardized_wrt_Population"] = stand_sol1
data["NTL_Normality_Divergence_wrt_Population"] = norm1
data["NTL_Mean_wrt_Population_Density"] = mean2
data["NTL_Std_Dev_wrt_Population_Density"] = std_dev2
data["NTL_SOL_wrt_Population_Density"] = sol2
data["NTL_SOL_Standardized_wrt_Population_Density"] = stand_sol2
data["NTL_Normality_Divergence_wrt_Population_Density"] = norm2

data.to_csv(path + "data_final.csv")
data.head()

"""### Past Data"""

ref_data = pd.read_csv(path + "data_final.csv", index_col=0)

data = pd.read_csv(path + "past_ntl_data.csv", index_col=0)
fips = set(data["FIPS"].tolist())

population_dict = {}
pop_density_dict = {}

for code in fips:
  temp = ref_data[ref_data["FIPS"] == code]
  if temp.empty == True:
    p = np.NaN
    d = np.NaN
  elif temp.empty == False:
    p = temp["Population"].tolist()[0]
    d = temp["Population_Density"].tolist()[0]
  population_dict[code] = p
  pop_density_dict[code] = d

print(population_dict)
print(pop_density_dict)

mean1 = []
std_dev1 = []
sol1 = []
stand_sol1 = []
mean2 = []
std_dev2 = []
sol2 = []
stand_sol2 = []

for row in data.itertuples():
  code = row.FIPS
  p = population_dict[code]
  dens = pop_density_dict[code]
  m = row.Mean
  d = row.Std_Dev
  s = row.Sum_of_Lights
  ss = row.Standard_SoL
  mean1.append(100000 * m/p)
  std_dev1.append(100000 * d/p)
  sol1.append(100000 * s/p)
  stand_sol1.append(100000 * ss/p)
  mean2.append(100000 * m/dens)
  std_dev2.append(100000 * d/dens)
  sol2.append(100000 * s/dens)
  stand_sol2.append(100000 * ss/dens)

data["Mean_wrt_Population"] = mean1
data["Std_Dev_wrt_Population"] = std_dev1
data["SOL_wrt_Population"] = sol1
data["SOL_Standardized_wrt_Population"] = stand_sol1
data["Mean_wrt_Population_Density"] = mean2
data["Std_Dev_wrt_Population_Density"] = std_dev2
data["SOL_wrt_Population_Density"] = sol2
data["SOL_Standardized_wrt_Population_Density"] = stand_sol2

data.to_csv(path + "past_ntl_data.csv")
data.head()

"""## Combining Past and Covid-19 Dataframes"""

curr = pd.read_csv(path + "data_final.csv",index_col=0)
past = pd.read_csv(path + "past_ntl_data.csv",index_col=0)

months = []
years = []

for row in past_data.itertuples():
  date = row.Date
  date_lst = date.split("-")
  months.append(float(date_lst[1]))
  years.append(float(date_lst[0]))

past["Month"] = months
past["Year"] = years

curr.columns

past.columns

past = past.rename(columns={'Mean':'NTL_Mean', 'Std_Dev': 'NTL_Std_Dev', 'Sum_of_Lights': 'NTL_SOL',
                            'Standard_SoL': 'NTL_SOL_Standardized', 'Mean_wrt_Population': 'NTL_Mean_wrt_Population',
                            'Std_Dev_wrt_Population': 'NTL_Std_Dev_wrt_Population', 'SOL_wrt_Population': 'NTL_SOL_wrt_Population',
                            'SOL_Standardized_wrt_Population': 'NTL_SOL_Standardized_wrt_Population',
                            'Mean_wrt_Population_Density': 'NTL_Mean_wrt_Population_Density',
                            'Std_Dev_wrt_Population_Density': 'NTL_Std_Dev_wrt_Population_Density',
                            'SOL_wrt_Population_Density': 'NTL_SOL_wrt_Population_Density',
                            'SOL_Standardized_wrt_Population_Density': 'NTL_SOL_Standardized_wrt_Population_Density'})

fips = set(past["FIPS"].tolist())

svi_dict = {}
state_dict = {}
county_dict = {}
land_dict = {}
population_dict = {}
pop_density_dict = {}

for code in fips:
  temp = curr[curr["FIPS"] == code]
  if temp.empty == True:
    v = np.NaN
    s = np.NaN
    c = np.NaN
    l = np.NaN
    p = np.NaN
    d = np.NaN
  elif temp.empty == False:
    v = temp["SVI"].tolist()[0]
    s = temp["State"].tolist()[0]
    c = temp["County"].tolist()[0]
    l = temp["County_Land_Area_mi2"].tolist()[0]
    p = temp["Population"].tolist()[0]
    d = temp["Population_Density"].tolist()[0]
  svi_dict[code] = v
  state_dict[code] = s
  county_dict[code] = c
  land_dict[code] = l
  population_dict[code] = p
  pop_density_dict[code] = d

svi_lst = []
state_lst = []
county_lst = []
land_lst = []
population_lst = []
pop_density_lst = []

for row in past.itertuples():
  fips = row.FIPS
  svi_lst.append(svi_dict[fips])
  state_lst.append(state_dict[fips])
  county_lst.append(county_dict[fips])
  land_lst.append(land_dict[fips])
  population_lst.append(population_dict[fips])
  pop_density_lst.append(pop_density_dict[fips])

past["SVI"] = svi_lst
past["State"] = state_lst
past["County"] = county_lst
past["County_Land_Area_mi2"] = land_lst
past["Population"] = population_lst
past["Population_Density"] = pop_density_lst

past["Total_Cases"] = [np.NaN] * 111888
past["Total_Deaths"] = [np.NaN] * 111888
past["New_Cases"] = [np.NaN] * 111888
past["New_Deaths"] = [np.NaN] * 111888
past["Series_Complete_Num"] = [np.NaN] * 111888
past["Series_Complete_Pct"] = [np.NaN] * 111888
past["Series_Complete_SVI"] = [np.NaN] * 111888
past["Booster_Complete_Num"] = [np.NaN] * 111888
past["Booster_Complete_Pct"] = [np.NaN] * 111888
past["Booster_Complete_SVI"] = [np.NaN] * 111888
past["Stay_at_home_order"] = [np.NaN] * 111888
past["Spending"] = [np.NaN] * 111888
past["Job_Postings"] = [np.NaN] * 111888
past["Employment_Rate"] = [np.NaN] * 111888
past["UI_Count"] = [np.NaN] * 111888
past["UI_Rate"] = [np.NaN] * 111888
past['NTL_Normality_Divergence'] = [np.NaN] * 111888
past["NTL_Normality_Divergence_wrt_Population"] = [np.NaN] * 111888
past["NTL_Normality_Divergence_wrt_Population_Density"] = [np.NaN] * 111888
past["Incidence_Rate"] = [np.NaN] * 111888
past["Death_Rate"] = [np.NaN] * 111888
past["Fatality_Ratio"] = [np.NaN] * 111888
past["Cumulative_Incidence_Rate"] = [np.NaN] * 111888
past["Cumulative_Death_Rate"] = [np.NaN] * 111888
past["Cumulative_Fatality_Ratio"] = [np.NaN] * 111888

past[['Date', 'County', 'State', 'FIPS', 'Total_Cases', 'Total_Deaths',
       'New_Cases', 'New_Deaths', 'Month', 'Year', 'SVI',
       'Series_Complete_Num', 'Series_Complete_Pct', 'Series_Complete_SVI',
       'Booster_Complete_Num', 'Booster_Complete_Pct', 'Booster_Complete_SVI',
       'Population', 'Stay_at_home_order', 'Spending', 'Job_Postings',
       'Employment_Rate', 'UI_Count', 'UI_Rate', 'NTL_Mean', 'NTL_Std_Dev',
       'NTL_SOL', 'NTL_SOL_Standardized', 'County_Land_Area_mi2',
       'Incidence_Rate', 'Death_Rate', 'Fatality_Ratio',
       'Cumulative_Incidence_Rate', 'Cumulative_Death_Rate',
       'Cumulative_Fatality_Ratio', 'Population_Density',
       'NTL_Normality_Divergence', 'NTL_Mean_wrt_Population',
       'NTL_Std_Dev_wrt_Population', 'NTL_SOL_wrt_Population',
       'NTL_SOL_Standardized_wrt_Population',
       'NTL_Normality_Divergence_wrt_Population',
       'NTL_Mean_wrt_Population_Density', 'NTL_Std_Dev_wrt_Population_Density',
       'NTL_SOL_wrt_Population_Density',
       'NTL_SOL_Standardized_wrt_Population_Density',
       'NTL_Normality_Divergence_wrt_Population_Density']]

past1 = past[(past["Year"] < 2020)]
past2 = past[(past["Year"] == 2020) & (past["Month"] < 3)]
past_rem = pd.concat([past1,past2])

all_data = pd.concat([past_rem,curr])
all_data.to_csv(path + "all_data.csv")

"""## Standardize Data

"""

df = pd.read_csv(path + "data_final.csv",index_col=0)
df.columns

cols = ['Total_Cases', 'Total_Deaths',
       'New_Cases', 'New_Deaths',
       'Series_Complete_Num', 'Series_Complete_Pct', 'Series_Complete_SVI',
       'Booster_Complete_Num', 'Booster_Complete_Pct', 'Booster_Complete_SVI',
       'Population', 'Spending', 'Job_Postings',
       'Employment_Rate', 'UI_Count', 'UI_Rate', 'NTL_Mean', 'NTL_Std_Dev',
       'NTL_SOL', 'NTL_SOL_Standardized', 'County_Land_Area_mi2',
       'Incidence_Rate', 'Death_Rate', 'Fatality_Ratio',
       'Cumulative_Incidence_Rate', 'Cumulative_Death_Rate',
       'Cumulative_Fatality_Ratio', 'Population_Density',
       'NTL_Normality_Divergence', 'NTL_Mean_wrt_Population',
       'NTL_Std_Dev_wrt_Population', 'NTL_SOL_wrt_Population',
       'NTL_SOL_Standardized_wrt_Population',
       'NTL_Normality_Divergence_wrt_Population',
       'NTL_Mean_wrt_Population_Density', 'NTL_Std_Dev_wrt_Population_Density',
       'NTL_SOL_wrt_Population_Density',
       'NTL_SOL_Standardized_wrt_Population_Density',
       'NTL_Normality_Divergence_wrt_Population_Density']

df_standard = df.copy()

for column in cols:
  df_standard[column] = stats.zscore(df_standard[column], nan_policy='omit')

df_standard.to_csv(path + "data_standardized.csv")
df_standard.head()

df = pd.read_csv(path + "all_data.csv", index_col=0)

cols = ['Total_Cases', 'Total_Deaths',
       'New_Cases', 'New_Deaths',
       'Series_Complete_Num', 'Series_Complete_Pct', 'Series_Complete_SVI',
       'Booster_Complete_Num', 'Booster_Complete_Pct', 'Booster_Complete_SVI',
       'Population', 'Spending', 'Job_Postings',
       'Employment_Rate', 'UI_Count', 'UI_Rate', 'NTL_Mean', 'NTL_Std_Dev',
       'NTL_SOL', 'NTL_SOL_Standardized', 'County_Land_Area_mi2',
       'Incidence_Rate', 'Death_Rate', 'Fatality_Ratio',
       'Cumulative_Incidence_Rate', 'Cumulative_Death_Rate',
       'Cumulative_Fatality_Ratio', 'Population_Density',
       'NTL_Normality_Divergence', 'NTL_Mean_wrt_Population',
       'NTL_Std_Dev_wrt_Population', 'NTL_SOL_wrt_Population',
       'NTL_SOL_Standardized_wrt_Population',
       'NTL_Normality_Divergence_wrt_Population',
       'NTL_Mean_wrt_Population_Density', 'NTL_Std_Dev_wrt_Population_Density',
       'NTL_SOL_wrt_Population_Density',
       'NTL_SOL_Standardized_wrt_Population_Density',
       'NTL_Normality_Divergence_wrt_Population_Density']

df_standard = df.copy()

for column in cols:
  df_standard[column] = stats.zscore(df_standard[column], nan_policy='omit')

df_standard.to_csv(path + "all_data_standardized.csv")
df_standard.head()

